{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Import Kaggle and Download data"
      ],
      "metadata": {
        "id": "wUT6XMEKfAIg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Let's get the fun started"
      ],
      "metadata": {
        "id": "mQT9GgGrfSAR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# installing and upgrading the \"kaggle\" package\n",
        "!pip install kaggle\n",
        "!pip install --upgrade --force-reinstall --no-deps kaggle"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ASbvCU0ye_wb",
        "outputId": "63eb6e92-0421-4f11-e78c-30a55fdc93cb"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (1.5.16)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle) (1.16.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from kaggle) (2023.7.22)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.27.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kaggle) (4.65.0)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle) (8.0.1)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle) (1.26.16)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle) (6.0.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle) (0.5.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.4)\n",
            "Collecting kaggle\n",
            "  Downloading kaggle-1.5.16.tar.gz (83 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.6/83.6 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: kaggle\n",
            "  Building wheel for kaggle (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for kaggle: filename=kaggle-1.5.16-py3-none-any.whl size=110685 sha256=45e0579495e45e3498abec88f9a1187dbe9fde79f22b96c1dd62393553ef5393\n",
            "  Stored in directory: /root/.cache/pip/wheels/43/4b/fb/736478af5e8004810081a06259f9aa2f7c3329fc5d03c2c412\n",
            "Successfully built kaggle\n",
            "Installing collected packages: kaggle\n",
            "  Attempting uninstall: kaggle\n",
            "    Found existing installation: kaggle 1.5.16\n",
            "    Uninstalling kaggle-1.5.16:\n",
            "      Successfully uninstalled kaggle-1.5.16\n",
            "Successfully installed kaggle-1.5.16\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Uploading the configuration file to authenticate Kaggle API access\n",
        "from google.colab import files\n",
        "files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        },
        "id": "TZL9tCG6e_fo",
        "outputId": "99a098a5-b94c-410e-be01-715917b710d6"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-c222dae7-9a15-4581-ab88-f0502b7b05d4\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-c222dae7-9a15-4581-ab88-f0502b7b05d4\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'kaggle.json': b'{\"username\":\"solafafadlallah\",\"key\":\"4d164dae88f65e5ac8385268e4e8016f\"}'}"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# configuring the Kaggle API authentication\n",
        "!rm -r ~/.kaggle\n",
        "!mkdir ~/.kaggle\n",
        "!mv ./kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SPw_uWW2fdN3",
        "outputId": "cc0e8f29-bc00-49b4-ddf4-352ebaf2cded"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rm: cannot remove '/root/.kaggle': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# downloading the data files related to the \"kernel-methods-ammi-2023\" competition to the current working directory\n",
        "!kaggle competitions download -c kernel-methods-ammi-2023"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R8Un82Reff1i",
        "outputId": "d1c2f80c-90ec-4278-8d6d-452741b625dd"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading kernel-methods-ammi-2023.zip to /content\n",
            " 99% 1.00M/1.01M [00:00<00:00, 1.50MB/s]\n",
            "100% 1.01M/1.01M [00:00<00:00, 1.52MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#extracting the files\n",
        "!unzip /content/kernel-methods-ammi-2023.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gh5E5o-xfiaB",
        "outputId": "1b8328fe-52bd-4f17-ddec-03150e340ef1"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/kernel-methods-ammi-2023.zip\n",
            "  inflating: Xte0.csv                \n",
            "  inflating: Xte0_mat100.csv         \n",
            "  inflating: Xte1.csv                \n",
            "  inflating: Xte1_mat100.csv         \n",
            "  inflating: Xte2.csv                \n",
            "  inflating: Xte2_mat100.csv         \n",
            "  inflating: Xtr0.csv                \n",
            "  inflating: Xtr0_mat100.csv         \n",
            "  inflating: Xtr1.csv                \n",
            "  inflating: Xtr1_mat100.csv         \n",
            "  inflating: Xtr2.csv                \n",
            "  inflating: Xtr2_mat100.csv         \n",
            "  inflating: Ytr0.csv                \n",
            "  inflating: Ytr1.csv                \n",
            "  inflating: Ytr2.csv                \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# importing the neccessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "import itertools\n",
        "import seaborn as sns\n",
        "from collections import defaultdict\n",
        "import cvxopt\n",
        "from itertools import product\n",
        "from scipy import optimize\n",
        "!pip install cvxopt\n",
        "!pip install qpsolvers\n",
        "from qpsolvers import solve_qp\n",
        "from sklearn.base import BaseEstimator, ClassifierMixin\n",
        "import timeit\n",
        "from sklearn.model_selection import cross_validate\n",
        "from numpy.lib.function_base import iterable\n",
        "from scipy.special import expit as sigmoid"
      ],
      "metadata": {
        "id": "Wbagks_Lfm5Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad470c43-342a-4991-daac-a39b1d112f26"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: cvxopt in /usr/local/lib/python3.10/dist-packages (1.3.1)\n",
            "Requirement already satisfied: qpsolvers in /usr/local/lib/python3.10/dist-packages (3.4.0)\n",
            "Requirement already satisfied: daqp>=0.5.1 in /usr/local/lib/python3.10/dist-packages (from qpsolvers) (0.5.1)\n",
            "Requirement already satisfied: ecos>=2.0.8 in /usr/local/lib/python3.10/dist-packages (from qpsolvers) (2.0.12)\n",
            "Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.10/dist-packages (from qpsolvers) (1.22.4)\n",
            "Requirement already satisfied: osqp>=0.6.2 in /usr/local/lib/python3.10/dist-packages (from qpsolvers) (0.6.2.post8)\n",
            "Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from qpsolvers) (1.10.1)\n",
            "Requirement already satisfied: scs>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from qpsolvers) (3.2.3)\n",
            "Requirement already satisfied: qdldl in /usr/local/lib/python3.10/dist-packages (from osqp>=0.6.2->qpsolvers) (0.1.7.post0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Obtaining the data"
      ],
      "metadata": {
        "id": "1fig0onGcZwA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#1st Data Set\n",
        "file_path = \"/content/Xtr0.csv\"\n",
        "Xtr0 = np.array(pd.read_csv(file_path, sep=\",\", index_col=0))\n",
        "file_path = \"/content/Ytr0.csv\"\n",
        "Ytr0 = 2*(np.array(pd.read_csv(file_path, index_col=0)).reshape(Xtr0.shape[0]))-1\n",
        "file_path = \"/content/Xte0.csv\"\n",
        "Xte0 = np.array(pd.read_csv(file_path, sep=\",\", index_col=0))\n",
        "\n",
        "\n",
        "#2nd Data Set\n",
        "file_path = \"/content/Xtr1.csv\"\n",
        "Xtr1 = np.array(pd.read_csv(file_path, sep=\",\", index_col=0))\n",
        "file_path = \"/content/Ytr1.csv\"\n",
        "Ytr1 = 2*(np.array(pd.read_csv(file_path, index_col=0)).reshape(Xtr1.shape[0]))-1\n",
        "file_path = \"/content/Xte1.csv\"\n",
        "Xte1 = np.array(pd.read_csv(file_path, sep=\",\", index_col=0))\n",
        "\n",
        "\n",
        "#3rd Data Set\n",
        "file_path = \"/content/Xtr2.csv\"\n",
        "Xtr2 = np.array(pd.read_csv(file_path, sep=\",\", index_col=0))\n",
        "file_path = \"/content/Ytr2.csv\"\n",
        "Ytr2 = 2*(np.array(pd.read_csv(file_path, index_col=0)).reshape(Xtr2.shape[0]))-1\n",
        "file_path = \"/content/Xte2.csv\"\n",
        "Xte2 = np.array(pd.read_csv(file_path, sep=\",\", index_col=0))\n"
      ],
      "metadata": {
        "id": "5tbwL-PXclzF"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def corspond(Seq, l):\n",
        "  '''\n",
        "  This function generates all possible sequences of length l using elements from Seq and creates\n",
        "  a dictionary that maps each sequence to its corresponding index.\n",
        "  '''\n",
        "  correspond = {}\n",
        "  cont = 0\n",
        "\n",
        "  for i in product(Seq, repeat = l):\n",
        "    j = ''\n",
        "    for m in range(l):\n",
        "        j = j + i[m]\n",
        "    correspond[j] = cont\n",
        "    cont = cont + 1\n",
        "  return correspond"
      ],
      "metadata": {
        "id": "Wf3hVodgOmA5"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def mismatch(l, n, correspond):\n",
        "\n",
        "  a = 4**l\n",
        "  b = np.zeros((a,a))\n",
        "  sequnce = list(correspond.keys())\n",
        "  for i in range(a):\n",
        "    sequnce1 = sequnce[i]\n",
        "    for j in range(a):\n",
        "      sequnce2 = sequnce[j]\n",
        "      ms = 0\n",
        "      cont = 0\n",
        "      while (ms <= n) and (cont <= l-1):\n",
        "        if sequnce1[cont] != sequnce2[cont]:\n",
        "          ms = ms + 1\n",
        "        cont = cont + 1\n",
        "      if ms <= n:\n",
        "          b[i,j] = 1\n",
        "  return b"
      ],
      "metadata": {
        "id": "NPaW-vTQOrx7"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Gram_mis_match(X, Xtest, corspond, l, mis_match):\n",
        "  '''\n",
        "  X: training dataset\n",
        "  X_test: test dataset\n",
        "  corspond: a dictionary that maps each sequence to its corresponding index\n",
        "  mismatch : mismatch matrix\n",
        "  '''\n",
        "  X_new = np.concatenate((X,Xtest), axis=0)\n",
        "  vect = np.zeros((X_new.shape[0],4**l))\n",
        "  for s in range(X_new.shape[0]):\n",
        "    for j in range((len(X_new[0][0]))-l+1):\n",
        "      var = X_new[s][0][j:j+l]\n",
        "      vect[s] = vect[s] + mis_match[corspond[var]]\n",
        "    vect[s]/=np.sqrt(np.dot(vect[s],vect[s]))\n",
        "\n",
        "  return np.dot(vect,vect.T)\n"
      ],
      "metadata": {
        "id": "4rKSP6GAsNga"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Kernel Normalization"
      ],
      "metadata": {
        "id": "fXQ7_OCPNUcn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def Kernel_Norm(K):\n",
        "  K_norm = K.copy()\n",
        "  for i in range(K.shape[0]):\n",
        "    for j in range(K.shape[1]):\n",
        "      K_norm[i,j] /= (K[i,i]*K[j,j])**(0.5)\n",
        "  return K_norm"
      ],
      "metadata": {
        "id": "9cu1PcazLWSl"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#kernel Ridge regression gives a 66.6% accurcy!"
      ],
      "metadata": {
        "id": "7KpZw5FHxIJr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ridge Regression"
      ],
      "metadata": {
        "id": "E5svWJYUNilB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Ridge_regression():\n",
        "\n",
        "  \"\"\"\n",
        "    This class implements the kernel ridge regression method for mismatch kernels.\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self, lmbd = 1.0, solver='closed_form', cores=None, k_mer = 6, mis_match_mat = None):\n",
        "    \"\"\"\n",
        "      - lmbd: Regularization parameter\n",
        "      - cores: mismatch correspondence matrix\n",
        "      - k_mer: k-mer length (Length of the sequence)\n",
        "      - mis_match_mat: The matrix of mismatches among all k-length sequences\n",
        "    \"\"\"\n",
        "    self.lmbd = lmbd\n",
        "    self.cores = cores\n",
        "    self.k_mer = k_mer\n",
        "    self.mis_match_mat = mis_match_mat\n",
        "\n",
        "  def fit(self, Xtr, Ytr, Xte):\n",
        "\n",
        "    \"\"\"\n",
        "      Xtr: Training data\n",
        "      Ytr: Target values\n",
        "      Xte: Test data\n",
        "    \"\"\"\n",
        "    self.Xtr = Xtr\n",
        "    self.Ytr = Ytr\n",
        "    self.Xte = Xte\n",
        "\n",
        "    N = self.Xtr.shape[0]\n",
        "\n",
        "    Reg_mat = self.lmbd*np.identity(N) #diagonal matrix with the regularization parameter lambda\n",
        "\n",
        "    K_mismatch = Gram_mis_match(self.Xtr, self.Xte, self.cores, self.k_mer, self.mis_match_mat)\n",
        "\n",
        "\n",
        "    K_mismatch =Kernel_Norm(K_mismatch)\n",
        "\n",
        "    split = N\n",
        "\n",
        "    self.K_mismatch_tr = K_mismatch[:split, :split]\n",
        "\n",
        "    self.K_mismatch_te = K_mismatch[split:, :split]\n",
        "\n",
        "    Bita = np.linalg.inv((self.K_mismatch_tr + Reg_mat)).dot(Ytr)\n",
        "\n",
        "    self.Bita = Bita\n",
        "\n",
        "\n",
        "  def pred(self):\n",
        "    Bita = self.Bita\n",
        "    K_te = self.K_mismatch_te.T\n",
        "    K_pred = np.dot(Bita, K_te)\n",
        "\n",
        "    self.K_pred = K_pred\n",
        "\n",
        "    return self.K_pred\n"
      ],
      "metadata": {
        "id": "CKS3p1LtNnJW"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Training the Data:"
      ],
      "metadata": {
        "id": "7NzTZ69ejJtT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('training first data set')\n",
        "sequence =['A', 'C', 'G', 'T'] #nucleotides: adenine, cytosine, guanine, and thymine\n",
        "k_mer = 7\n",
        "m = 1\n",
        "#m is the number of allowed mismatches in the sequences. It defines the maximum number of positions at which two sequences can differ and still be considered similar\n",
        "\n",
        "correspond = corspond(sequence, k_mer)\n",
        "mismatch_mat = mismatch(k_mer, m, correspond)\n",
        "lmbd = 1\n",
        "\n",
        "RR = Ridge_regression(lmbd = 1, cores = correspond, k_mer = k_mer, mis_match_mat = mismatch_mat)\n",
        "\n",
        "RR.fit(Xtr0, Ytr0, Xte0)\n",
        "\n",
        "y_pred = (np.sign(RR.pred())).astype(\"int8\")\n",
        "\n",
        "y_pred_df0 = pd.DataFrame({\"id\": range(1000), \"Bound\": y_pred.T})\n",
        "\n",
        "\n",
        "\n",
        "print('training second data set')\n",
        "\n",
        "\n",
        "\n",
        "sequence = ['A', 'C', 'G', 'T'] #nucleotides: adenine, cytosine, guanine, and thymine\n",
        "k_mer = 7\n",
        "m = 1\n",
        "RR = Ridge_regression(lmbd = 1, cores = correspond, k_mer = k_mer, mis_match_mat = mismatch_mat)\n",
        "\n",
        "RR.fit(Xtr1, Ytr1, Xte1)\n",
        "\n",
        "y_pred = (np.sign(RR.pred())).astype(\"int8\")\n",
        "\n",
        "y_pred_df1 = pd.DataFrame({\"id\": range(1000), \"Bound\": y_pred.T})\n",
        "\n",
        "\n",
        "\n",
        "print('training third data set')\n",
        "\n",
        "\n",
        "\n",
        "sequence = ['A', 'C', 'G', 'T'] #nucleotides: adenine, cytosine, guanine, and thymine\n",
        "k_mer = 7\n",
        "m = 3\n",
        "RR = Ridge_regression(lmbd = 0.07, cores = correspond, k_mer = k_mer, mis_match_mat = mismatch_mat)\n",
        "\n",
        "RR.fit(Xtr2, Ytr2, Xte2)\n",
        "\n",
        "y_pred = (np.sign(RR.pred())).astype(\"int8\")\n",
        "\n",
        "y_pred_df2 = pd.DataFrame({\"id\": range(1000), \"Bound\": y_pred.T})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ezwR4WtjTpN",
        "outputId": "39724e03-69d4-4fbe-8284-fe12939d0a99"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training first data set\n",
            "training second data set\n",
            "training third data set\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Submitting the results"
      ],
      "metadata": {
        "id": "gXxvDwYQqzt7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_pred = pd.concat([y_pred_df0,y_pred_df1,y_pred_df2])\n",
        "df_pred = df_pred.replace(-1,0)\n",
        "df_pred.to_csv('Y_pred_RR', index = False)"
      ],
      "metadata": {
        "id": "lWHU0Mjeq5EY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#let's try to normalize the kernels"
      ],
      "metadata": {
        "id": "yq36rdGJ1ULZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Kernel Normalization"
      ],
      "metadata": {
        "id": "iwO9RyRKJ5Gi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def Kernel_Norm(K):\n",
        "  K_norm = K.copy()\n",
        "  for i in range(K.shape[0]):\n",
        "    for j in range(K.shape[1]):\n",
        "      K_norm[i,j] /= (K[i,i]*K[j,j])**(0.5)\n",
        "  return K_norm"
      ],
      "metadata": {
        "id": "X8j6veRGJ9vk"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Lets do logistic regression"
      ],
      "metadata": {
        "id": "EtyHaIcVUcum"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Before training"
      ],
      "metadata": {
        "id": "6vDHlL59FjHy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sequence =['A', 'C', 'G', 'T'] #nucleotides: adenine, cytosine, guanine, and thymine\n",
        "k_mer = 7\n",
        "m = 1\n",
        "#m is the number of allowed mismatches in the sequences. It defines the maximum number of positions at which two sequences can differ and still be considered similar\n",
        "\n",
        "correspond = corspond(sequence, k_mer)\n",
        "mismatch_mat = mismatch(k_mer, m, correspond)"
      ],
      "metadata": {
        "id": "YqkYtMurFlK6"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Here we do the SVM"
      ],
      "metadata": {
        "id": "QjxWre8-lZ2-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Utilities"
      ],
      "metadata": {
        "id": "dyrHoDs40fng"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cvxopt\n",
        "\n",
        "def cvxopt_qp(P, q, G, h, A, b):\n",
        "    P = .5 * (P + P.T)\n",
        "    cvx_matrices = [\n",
        "        cvxopt.matrix(M) if M is not None else None for M in [P, q, G, h, A, b]\n",
        "    ]\n",
        "    #cvxopt.solvers.options['show_progress'] = False\n",
        "    solution = cvxopt.solvers.qp(*cvx_matrices, options={'show_progress': False})\n",
        "    return np.array(solution['x']).flatten()\n",
        "\n",
        "solve_qp = cvxopt_qp"
      ],
      "metadata": {
        "id": "0ZrDgGvP0iCA"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def svm_dual_soft_to_qp_kernel(K, y, C=1):\n",
        "    n = K.shape[0]\n",
        "    assert (len(y) == n)\n",
        "\n",
        "    # Dual formulation, soft margin\n",
        "    P = y[None]*K*y[:,None]\n",
        "    # As a regularization, we add epsilon * identity to P\n",
        "    eps = 1e-12\n",
        "    P += eps * np.eye(n)\n",
        "    q = - np.ones(n)\n",
        "    G = np.vstack([-np.eye(n), np.eye(n)])\n",
        "    h = np.hstack([np.zeros(n), C * np.ones(n)])\n",
        "    A = y[np.newaxis, :]\n",
        "    b = np.array([0.])\n",
        "    return P, q, G, h, A, b"
      ],
      "metadata": {
        "id": "FbVQ1roVzj3g"
      },
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class KernelSVM():\n",
        "    '''\n",
        "    Kernel SVM Classification\n",
        "\n",
        "    Methods\n",
        "    ----\n",
        "    fit\n",
        "    predict\n",
        "    '''\n",
        "    def __init__(self, C=0.1, cores = None, k_mer = 6 ,mis_match_mat = None, **kwargs):\n",
        "\n",
        "        super().__init__(**kwargs)\n",
        "        self.mis_match_mat = mis_match_mat\n",
        "        self.cores = cores\n",
        "        self.k_mer = k_mer\n",
        "        self.lbda = C\n",
        "\n",
        "    def fit_K(self, Xtr, Xte, y, tol=1e-3):\n",
        "        # Solve dual problem\n",
        "        self.Xtr = Xtr\n",
        "        self.Xte = Xte\n",
        "        #self.lbda = lbda\n",
        "\n",
        "\n",
        "        N = self.Xtr.shape[0]\n",
        "\n",
        "\n",
        "        K_mismatch = Gram_mis_match(self.Xtr, self.Xte, self.cores, self.k_mer, self.mis_match_mat)\n",
        "        self.K_mismatch = K_mismatch\n",
        "\n",
        "        split = N\n",
        "\n",
        "        self.K_mismatch_tr = K_mismatch[:split, :split]\n",
        "\n",
        "        self.K_mismatch_te = K_mismatch[split:, split:]\n",
        "\n",
        "        self.alpha = solve_qp(*svm_dual_soft_to_qp_kernel(self.K_mismatch_tr, y, C=self.lbda))\n",
        "        y = 2 * y - 1\n",
        "\n",
        "        n = len(y)\n",
        "\n",
        "        q = - y.astype(float)\n",
        "        P = self.K_mismatch_tr\n",
        "        G = np.zeros((2 * n, n))\n",
        "        G[:n, :] = - np.diag(y)\n",
        "        G[n:, :] = np.diag(y)\n",
        "        h = np.zeros(2 * n)\n",
        "        h[n:] = 1 / (2 * self.lbda * n)\n",
        "        #self.alpha = qpsolvers.solve_qp(P, q, G, h, solver='cvxopt')\n",
        "\n",
        "        # Compute support vectors and bias b\n",
        "        sv = np.logical_and((self.alpha > tol), (self.lbda - self.alpha > tol))\n",
        "        self.bias = y[sv] - self.K_mismatch_tr[sv].dot(self.alpha * y)\n",
        "        self.bias = self.bias.mean()\n",
        "\n",
        "        self.support_vector_indices = np.nonzero(sv)[0]\n",
        "        self.fitted_ = True\n",
        "\n",
        "        return self\n",
        "\n",
        "    def decision_function_K(self, K_x):\n",
        "        K_x = self.K_mismatch_te\n",
        "        return K_x@(self.alpha[:len(self.K_mismatch_te)])\n",
        "\n",
        "    def predict(self):\n",
        "        print(self.alpha.shape, self.K_mismatch_te.shape, self.bias)\n",
        "        return np.sign(self.decision_function_K(self.K_mismatch_te))"
      ],
      "metadata": {
        "id": "g-mdchkslcy2"
      },
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sequence =['A', 'C', 'G', 'T'] #nucleotides: adenine, cytosine, guanine, and thymine\n",
        "k_mer = 7\n",
        "m = 1\n",
        "#m is the number of allowed mismatches in the sequences. It defines the maximum number of positions at which two sequences can differ and still be considered similar\n",
        "\n",
        "correspond = corspond(sequence, k_mer)\n",
        "mismatch_mat = mismatch(k_mer, m, correspond)"
      ],
      "metadata": {
        "id": "OasW-XYRGZXb"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SVM = KernelSVM(C=0.1, cores = correspond, k_mer = k_mer, mis_match_mat = mismatch_mat)"
      ],
      "metadata": {
        "id": "pc5ttX1PGZOF"
      },
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import qpsolvers"
      ],
      "metadata": {
        "id": "OoTwg-0yaBVb"
      },
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lbda = 0.1"
      ],
      "metadata": {
        "id": "ZknWkG1Ndcck"
      },
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SVM.fit_K(Xtr0, Xte0, Ytr0)"
      ],
      "metadata": {
        "id": "OUSIKqvZIoyj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def change_sign(x):\n",
        "    return 2 * x - 1"
      ],
      "metadata": {
        "id": "8oBVZE0xvPoK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def conv_to_binary(x):\n",
        "    return ((x + 1) / 2).astype(int)"
      ],
      "metadata": {
        "id": "yVW-FDoTvCGD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Logis_Regression(BaseEstimator, ClassifierMixin):\n",
        "    \"\"\"\n",
        "    by using BaseEstimator and ClassifierMixin, the Logis_regression class becomes a scikit-learn-compatible classifier,\n",
        "    which means it can be easily integrated into scikit-learn pipelines, work well with other scikit-learn components,\n",
        "    and leverage the tools and utilities provided by scikit-learn to streamline the machine learning workflow.\n",
        "    \"\"\"\n",
        "    def __init__(self, iter_max=20, tol=1E-6, lmbd=1.0):\n",
        "\n",
        "        self.lmbd = lmbd\n",
        "        self.tol = tol\n",
        "        self.iter_max = iter_max\n",
        "\n",
        "    @property\n",
        "    def PWISE(self):\n",
        "        return True\n",
        "\n",
        "    def fit(self, Ker, y):\n",
        "        \"\"\"\n",
        "        The fit method of the class, used for training the Kernel Logistic Regression model.\n",
        "\n",
        "        - K is the kernel matrix\n",
        "        - y is the target labels.\n",
        "        \"\"\"\n",
        "        param = np.zeros(len(Ker)) #variable as an array of zeros with the same length as the Kernel matrix\n",
        "        y = change_sign(y)\n",
        "\n",
        "        for i in range(self.iter_max):\n",
        "            Prob_t = - sigmoid(- y * (Ker @ param)) #Computing the sigmoid for each entry of the vector\n",
        "            Weight_t = sigmoid(Ker @ param) * sigmoid(-Ker @ param) #calculating the weight for each sample using the logistic sigmoid function.\n",
        "            Inter = Ker @ param - Prob_t * y / Weight_t #An intermediate variable which is used in the optimization process.\n",
        "\n",
        "            param_update = K_RR(Ker, Inter, Weight_t, lbda=self.lbda)\n",
        "\n",
        "            d = np.linalg.norm(param_update - param)\n",
        "            param = param_update\n",
        "\n",
        "            if d < self.tol:\n",
        "                break\n",
        "\n",
        "        self.param_ = param\n",
        "        self.fitted_ = True\n",
        "        self.Ker_fit_ = Ker\n",
        "\n",
        "        return self\n",
        "\n",
        "    def predict(self, Ker):\n",
        "        return conv_to_binary(np.sign(Ker @ self.param_))"
      ],
      "metadata": {
        "id": "CpBmFvpyvGNc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Implementing the TRIENODE"
      ],
      "metadata": {
        "id": "JXm-_ORdu8iT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# A Trie is a tree-like data structure used for efficient storage and retrieval of strings.\n",
        "# Each node in the Trie represents a single character, and the path from the root to a particular node forms a string.\n",
        "# The idea is that all strings sharing common prefix should come from a common node\n",
        "\"\"\"\n",
        "Trie Nodes have the following characteristics:\n",
        "\n",
        "  - Depth: Each node has a depth indicating its position in the string.\n",
        "  - Counts: Nodes can store counts or information associated with the string that corresponds\n",
        "    to the path from the root to that node.\n",
        "  - Children: Each node can have children representing different characters.\n",
        "\"\"\"\n",
        "\n",
        "# The mismatch kernel is constructed using a Trie data structure for efficient matching of subsequences"
      ],
      "metadata": {
        "id": "YdTaTC5BvM9O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class trinode():\n",
        "  \"\"\"\n",
        "  This class trinode represents a single node in the Trie data structure\n",
        "  \"\"\"\n",
        "  def __init__(self, dpth = 0):\n",
        "    self.dpth = dpth\n",
        "    self.conts = {} #A dictionary that stores the counts of occurrences of sequences represented by this node\n",
        "    self.children = defaultdict(self.create_) #A defaultdict where the keys are characters (e.g., 'A', 'C', 'G', 'T') and the values are TrieNode objects.\n",
        "\n",
        "  def create_(self):\n",
        "    return trinode(dpth = self.dpth + 1)\n",
        "\n",
        "  def leaf_(self):\n",
        "    return len(self.children)==0\n",
        "\n",
        "  def __iter__(self):\n",
        "    \"\"\"\n",
        "    This method allows for iteration over the Trie starting from the current node.\n",
        "    \"\"\"\n",
        "    yield self  #When iterating over a TrieNode object, it yields itself first.\n",
        "\n",
        "    #Now, iterating over its children and their grandchildren using a recursive loop.\n",
        "\n",
        "    for chld in self.children.values():\n",
        "      for gran_chld in chld:\n",
        "        yield gran_chld\n",
        "    \"\"\"\n",
        "    Iterating over all nodes in the Trie.\n",
        "    \"\"\""
      ],
      "metadata": {
        "id": "cXq9T9xCvT9p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class tri:\n",
        "  def __init__(self, len_sequence):\n",
        "    self.rot = trinode() #creating the root node of the Trie using the trinode class.\n",
        "    self.len_sequence = len_sequence\n",
        "\n",
        "\n",
        "  def add_(self, seq_id, seq, n_mismatch): #This method adds a new sequence to the Trie.\n",
        "    \"\"\"\n",
        "     - seq_id: Sequence identifier\n",
        "     - seq: Sequence\n",
        "     - n_mismatch: The number of mismatches associated with the sequence.\n",
        "    \"\"\"\n",
        "    nod = self.rot\n",
        "\n",
        "    for i in seq:\n",
        "      nod = nod.childern[i]\n",
        "\n",
        "    if seq_id not in nod.conts:\n",
        "      nod.conts[seq_id] = n_mismatch\n",
        "    else:\n",
        "      nod.conts[seq_id] = min(nod.conts[seq_id], n_mismatch)\n",
        "\n",
        "    @property\n",
        "    def nods(self):\n",
        "      for nod in self.rot:\n",
        "        yield nod\n",
        "\n",
        "    @property\n",
        "    def nod_num(self):\n",
        "      return sum(1 for i in self.nods)\n",
        "\n",
        "    @property\n",
        "    def lev(self):\n",
        "      for nod in self.nods:\n",
        "        if nod.leaf_():\n",
        "          yield nod\n",
        "\n",
        "    @property\n",
        "    def lef_num(self):\n",
        "      return sum(1 for i in self.lev)"
      ],
      "metadata": {
        "id": "KfXFJo5cvXGL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class mis_match_Kernel:\n",
        "  def __init__(self, k_mer, n_mismatch=1, w=None):\n",
        "    self.k_mer = k_mer\n",
        "    self.w = w\n",
        "    self.trie = tri(k_mer)\n",
        "    self.n_mismatch = n_mismatch\n",
        "    self.next_seq_id = 0\n",
        "    self.seq_fitt = {}\n",
        "\n",
        "    self.fitt = False\n",
        "    self.fitt_on = None\n",
        "    self.sequen = ['A','C','G','T']\n",
        "\n",
        "    def fit(self, sequence):\n",
        "      for i in tqdm(sequence):\n",
        "        self.strng_fit(i)\n",
        "      self.fitt = True\n",
        "      self.fitt_on = sequence\n",
        "      return self.build_k()\n",
        "\n",
        "    def predict(self, m):\n",
        "      for i in m:\n",
        "        self.strng_fit(i)\n",
        "      return self.build_k(m, self.fitt_on)\n",
        "\n",
        "    def strng_fit(self, strn):\n",
        "      if i in self.seq_fitt:\n",
        "        return\n",
        "      seq_id = self.next_seq_id\n",
        "      self.next_seq_id +=1\n",
        "      self.strng_fit[i] = seq_id\n",
        "\n",
        "      for sub_ in self.substr(s, self.k_mer):\n",
        "        for i in range (len (sub_)):\n",
        "          for l in self.sequen:\n",
        "            mis_match = l == sub_[i]\n",
        "            sub_copy = sub_[:i] + l + sub_[i+1:]\n",
        "            self.tri.add_(seq_id, sub_copy, int(mis_match))\n",
        "\n",
        "    def build_k(self, m, sequ):\n",
        "      m_id = [\n",
        "          self.strng_fit[t] for t in m\n",
        "      ]\n",
        "\n",
        "      seque_id = [ self.strng_fit[i] for i in sequ]\n",
        "\n",
        "      dot_ = defaultdict(float)\n",
        "      sq_norm = defaultdict(float)\n",
        "\n",
        "      w = self.w or 1.0\n",
        "      set_m_id = set(m_id)\n",
        "      set_sequ_id = set(seque_id)\n",
        "      all = set_m_id | set_sequ_id\n",
        "\n",
        "      a = dict(iterable=self.tri.leaf_, total = self.tri.lef_num)\n",
        "\n",
        "      for N in tqdm(**a):\n",
        "        N_id = set(N.conts.keys())\n",
        "\n",
        "        for idx in N_id & all:\n",
        "          sq_norm [idx] +=w**(2*N.conts[idx])\n",
        "\n",
        "        for idx in N_id & set_m_id:\n",
        "          for s_ in N_id & set_sequ_id:\n",
        "            dot = w**(N.conts[idx])\n",
        "            dot_[idx, s_] += dot\n",
        "\n",
        "        K = np.zeros((len(m), len(sequ)))\n",
        "\n",
        "        for a, i_idx in enumerate(m_id):\n",
        "          for b, idx_ in enumerate(seque_id):\n",
        "            K[a,b] = dot_[i_idx, idx_]/np.sqrt(sq_norm[i_idx]*sq_norm[idx_])\n",
        "        return K\n",
        "\n",
        "\n",
        "        @staticmethod\n",
        "\n",
        "        def substr(s, k):\n",
        "          return [s[a:a+k] for a in range(len(s)-k+1)]"
      ],
      "metadata": {
        "id": "J9uVHz57vZaw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}